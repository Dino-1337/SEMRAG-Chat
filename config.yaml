# LLM Configuration
llm:
  model: "mistral:7b"
  base_url: "http://localhost:11434"
  temperature: 0.7
  max_tokens: 1000

# Semantic Chunking Parameters
chunking:
  similarity_threshold: 0.45
  max_chunk_tokens: 800
  sub_chunk_tokens: 600
  chunk_overlap: 128
  buffer_size: 8

# Knowledge Graph Parameters
knowledge_graph:
  min_entity_frequency: 1
  community_resolution: 1.0

# Retrieval Parameters
retrieval:
  local_search:
    top_k: 5
    similarity_threshold: 0.6
  global_search:
    top_k: 3
    similarity_threshold: 0.5
  combine_strategy: "weighted"
